{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72379cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import wildboar\n",
    "from wildboar.transform import RocketTransform, HydraTransform, DiffTransform\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import StandardScaler  # <-- Only from sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)   ## For random shapelet forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0dead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get file names\n",
    "file = \"source/binded_file\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03c87ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_and_trim(df):\n",
    "    # Define the desired size per group\n",
    "    desired_size = 900\n",
    "\n",
    "    # create an empty DataFrame to hold the trimmed data\n",
    "    trimmed_df = pd.DataFrame()\n",
    "\n",
    "    # Group the dataframe by 'sample_ID' and iterate over the groups\n",
    "    for sample_ID, group in df.groupby('id1'):\n",
    "        # If the size of the group is larger than the desired size, take the first 'desired_size' rows\n",
    "        if len(group) > desired_size:\n",
    "            group = group.iloc[:desired_size]\n",
    "        # Append the group to the trimmed dataframe\n",
    "        trimmed_df = pd.concat([trimmed_df, group], ignore_index=True)\n",
    "\n",
    "    return trimmed_df\n",
    "\n",
    "pred_vars = ['id1', 'Brake','Accel', 'Lat_Pos', 'Speed',  'Wheel_Rate' ,\n",
    "             'gaze_unif_x','gaze_unif_y', 'gaze_unif_z', 'yaw', 'pitch', \n",
    "                'gaze_valid', 'gaze_orig_x','gaze_orig_y', 'gaze_orig_z', 'gaze_orig_valid', \n",
    "                'blinks','last_blink_dur','left_eye_open_mm','right_eye_open_mm','left_open_valid','right_open_valid'\n",
    "                , 'head_pos_x', 'head_pos_y', 'head_pos_z','head_pos_valid','inter_pup_dist',\n",
    "                'left_pupil_dia', 'left_pup_vis','right_pupil_dia', 'right_pup_vis']\n",
    "x_vars = ['Brake','Accel', 'Lat_Pos', 'Speed','Wheel_Rate',\n",
    "          'gaze_unif_x','gaze_unif_y', 'gaze_unif_z', 'yaw', 'pitch', \n",
    "            'gaze_valid','gaze_orig_x','gaze_orig_y', 'gaze_orig_z', \n",
    "            'gaze_orig_valid', 'blinks','last_blink_dur','left_eye_open_mm'\n",
    "            ,'right_eye_open_mm', 'left_open_valid','right_open_valid',\n",
    "            'head_pos_x', 'head_pos_y', 'head_pos_z','head_pos_valid','inter_pup_dist',\n",
    "            'left_pupil_dia', 'left_pup_vis','right_pupil_dia', 'right_pup_vis']\n",
    "y_vars = ['Condition','id1']\n",
    "status_names = ['status1','status2','status3','status4','status5','status6','status7','status8','status9','status10']\n",
    "\n",
    "\n",
    "cur_file = file\n",
    "data = pd.read_csv(cur_file)\n",
    "data = data.rename(columns={'CFS.Brake.Pedal.Force': 'Brake', \n",
    "                         'CFS.Accelerator.Pedal.Position': 'Accel', \n",
    "                         'LaneDev2': 'Lat_Pos',\n",
    "                         'VDS.Veh.Speed': 'Speed',\n",
    "                         'CFS.Steering.Wheel.Angle': 'Wheel_Angle',\n",
    "                         'CFS.Steering.Wheel.Angle.Rate': 'Wheel_Rate',\n",
    "                         'Output.FovioDMEResults.dgaze.unified.gaze.direction.x': 'gaze_unif_x', \n",
    "                            'Output.FovioDMEResults.dgaze.unified.gaze.direction.y': 'gaze_unif_y', \n",
    "                            'Output.FovioDMEResults.dgaze.unified.gaze.direction.z': 'gaze_unif_z',\n",
    "                            'Output.FovioDMEResults.dgaze.unified.gaze.direction.deg.yaw.deg': 'yaw',\n",
    "                            'Output.FovioDMEResults.dgaze.unified.gaze.direction.deg.pitch.d': 'pitch',\n",
    "                            'Output.FovioDMEResults.dgaze.unified.gaze.direction.valid': 'gaze_valid',\n",
    "                            'Output.FovioDMEResults.dgaze.unified.gaze.origin.m.x': 'gaze_orig_x',\n",
    "                            'Output.FovioDMEResults.dgaze.unified.gaze.origin.m.y': 'gaze_orig_y',\n",
    "                            'Output.FovioDMEResults.dgaze.unified.gaze.origin.m.z': 'gaze_orig_z',\n",
    "                            'Output.FovioDMEResults.dgaze.unified.gaze.origin.valid' : 'gaze_orig_valid',\n",
    "                            'Output.FovioDMEResults.dme.core.eyelid.blink.counter': 'blinks',\n",
    "                            'Output.FovioDMEResults.dme.core.eyelid.last.blink.duration.us' : 'last_blink_dur',\n",
    "                            'Output.FovioDMEResults.dme.core.eyelid.left.eyelid.opening.mm' : 'left_eye_open_mm',\n",
    "                            'Output.FovioDMEResults.dme.core.eyelid.right.eyelid.opening.mm' : 'right_eye_open_mm',\n",
    "                            'Output.FovioDMEResults.dme.core.eyelid.left.eyelid.opening.vali' : 'left_open_valid',\n",
    "                            'Output.FovioDMEResults.dme.core.eyelid.right.eyelid.opening.val' : 'right_open_valid',\n",
    "                            'Output.FovioDMEResults.dme.core.head.head.pose.rotation.x.deg' : 'head_pos_x',\n",
    "                            'Output.FovioDMEResults.dme.core.head.head.pose.rotation.y.deg' : 'head_pos_y',\n",
    "                            'Output.FovioDMEResults.dme.core.head.head.pose.rotation.z.deg' : 'head_pos_z',\n",
    "                            'Output.FovioDMEResults.dme.core.head.head.pose.valid': 'head_pos_valid',\n",
    "                            'Output.FovioDMEResults.dme.core.pupil.inter.pupil.distance.mm' : 'inter_pup_dist',\n",
    "                            'Output.FovioDMEResults.dme.core.pupil.left.pupil.diameter.mm': 'left_pupil_dia',\n",
    "                            'Output.FovioDMEResults.dme.core.pupil.left.pupil.visible' : 'left_pup_vis',\n",
    "                            'Output.FovioDMEResults.dme.core.pupil.right.pupil.diameter.mm': 'right_pupil_dia',\n",
    "                            'Output.FovioDMEResults.dme.core.pupil.right.pupil.visible' : 'right_pup_vis'\n",
    "                            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4678b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim data\n",
    "data = check_and_trim(data)\n",
    "\n",
    "# build 3D array for ALL samples\n",
    "ids = data['id1'].unique()\n",
    "n_samples = len(ids)\n",
    "n_vars = len(x_vars)\n",
    "timesteps = 900 # change size to desired group size\n",
    "\n",
    "X_all = np.zeros((n_samples, n_vars, timesteps))\n",
    "y_all = np.zeros(n_samples)\n",
    "# to store the ids and the indices of that id \n",
    "id_idx_match = {}\n",
    "for i in range(len(ids)):\n",
    "    id_ = ids[i]\n",
    "    id_idx_match[id_] = i\n",
    "\n",
    "# reshaping the data into 3d arrays X_all and y_all\n",
    "i = 0\n",
    "for cur_id in ids:\n",
    "    ji = 0\n",
    "    for j in x_vars:\n",
    "        X_all[i, ji, :] = data.loc[data['id1'] == cur_id][j]\n",
    "        ji = ji + 1\n",
    "    y_all[i] = data.loc[data['id1'] == cur_id]['Condition'].iloc[0]\n",
    "    i = i + 1\n",
    "\n",
    "# finding indices for splits and using only those indices\n",
    "for a in range(1, 11):\n",
    "    sp = status_names[a-1]\n",
    "    train_ids = data.loc[data[sp] == 't', 'id1'].unique()\n",
    "    test_ids = data.loc[data[sp] == 'v', 'id1'].unique()\n",
    "    train_idx = [id_idx_match[id_] for id_ in train_ids]\n",
    "    test_idx = [id_idx_match[id_] for id_ in test_ids]\n",
    "    train_X = X_all[train_idx]\n",
    "    train_y = y_all[train_idx]\n",
    "    test_X = X_all[test_idx]\n",
    "    test_y = y_all[test_idx]\n",
    "\n",
    "    hydra_diff = make_pipeline(\n",
    "        make_union(\n",
    "            RocketTransform(n_kernels=5000, random_state=1234, n_jobs=-1),\n",
    "            make_pipeline(\n",
    "                DiffTransform(),\n",
    "                HydraTransform(n_groups=32, random_state=1234, n_jobs=-1),\n",
    "            ),\n",
    "        ),\n",
    "        StandardScaler(),\n",
    "        LogisticRegression(random_state = 1234, max_iter = 300),\n",
    "    )\n",
    "\n",
    "    hydra_diff.fit(train_X, train_y)\n",
    "    y_pred = hydra_diff.predict(test_X)\n",
    "    y_score = hydra_diff.predict_proba(test_X)[:, 1]\n",
    "    roc_auc = roc_auc_score(test_y, y_score)\n",
    "    print(f\"Split {a} Test ROC AUC:\", roc_auc)\n",
    "\n",
    "    # saving results\n",
    "    results_df = pd.DataFrame({\n",
    "        'id1': test_ids,\n",
    "        'predicted_prob': y_score,\n",
    "        'target': test_y,\n",
    "        'pred': y_pred\n",
    "    })\n",
    "    results_df.to_csv(f'destination/results/rocketresults_combined{a}.csv', index=False)\n",
    "    \n",
    "    # roc curve\n",
    "    fpr, tpr, thresholds = roc_curve(test_y, y_score)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, label=f'Rocket+Logistic (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC Curve Vehicle 60s Split {a}')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'destination/ROCs/Split{a}.png')\n",
    "    plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
