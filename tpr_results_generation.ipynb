{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a101d0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all required libraries\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# loading the results for random forest and xgboost\n",
    "# 15s\n",
    "results1_rf = pd.read_csv(\"rf_results1.csv\")\n",
    "results2_rf = pd.read_csv(\"rf_results2.csv\")\n",
    "results3_rf = pd.read_csv(\"rf_results3.csv\")\n",
    "results4_rf = pd.read_csv(\"rf_results4.csv\")\n",
    "results5_rf = pd.read_csv(\"rf_results5.csv\")\n",
    "results6_rf = pd.read_csv(\"rf_results6.csv\")\n",
    "results7_rf = pd.read_csv(\"rf_results7.csv\")\n",
    "results8_rf = pd.read_csv(\"rf_results8.csv\")\n",
    "results9_rf = pd.read_csv(\"rf_results9.csv\")\n",
    "results10_rf = pd.read_csv(\"rf_results10.csv\")\n",
    "\n",
    "\n",
    "results1_xgb = pd.read_csv(\"xgb_results1.csv\")\n",
    "results2_xgb = pd.read_csv(\"xgb_results2.csv\")\n",
    "results3_xgb = pd.read_csv(\"xgb_results3.csv\")\n",
    "results4_xgb = pd.read_csv(\"xgb_results4.csv\")\n",
    "results5_xgb = pd.read_csv(\"xgb_results5.csv\")\n",
    "results6_xgb = pd.read_csv(\"xgb_results6.csv\")\n",
    "results7_xgb = pd.read_csv(\"xgb_results7.csv\")\n",
    "results8_xgb = pd.read_csv(\"xgb_results8.csv\")\n",
    "results9_xgb = pd.read_csv(\"xgb_results9.csv\")\n",
    "results10_xgb = pd.read_csv(\"xgb_results10.csv\")\n",
    "\n",
    "results1_rocket = pd.read_csv(\"rocketresults_vehicle1.csv\")\n",
    "results2_rocket = pd.read_csv(\"rocketresults_vehicle2.csv\")\n",
    "results3_rocket = pd.read_csv(\"rocketresults_vehicle3.csv\")\n",
    "results4_rocket = pd.read_csv(\"rocketresults_vehicle4.csv\")\n",
    "results5_rocket = pd.read_csv(\"rocketresults_vehicle5.csv\")\n",
    "results6_rocket = pd.read_csv(\"rocketresults_vehicle6.csv\")\n",
    "results7_rocket = pd.read_csv(\"rocketresults_vehicle7.csv\")\n",
    "results8_rocket = pd.read_csv(\"rocketresults_vehicle8.csv\")\n",
    "results9_rocket = pd.read_csv(\"rocketresults_vehicle9.csv\")\n",
    "results10_rocket = pd.read_csv(\"rocketresults_vehicle10.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88bb3d4e",
   "metadata": {},
   "source": [
    "REPEAT EVERYTHING FOR EYE AND THEN COMBINED AND CHANGE NECESSARY THINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a4065d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f468f5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binding all results files for a model and calculating max true positive rate for each split\n",
    "# random forest \n",
    "results_list_rf = [results1_rf, results2_rf, results3_rf, results4_rf, results5_rf,\n",
    "                results6_rf, results7_rf, results8_rf, results9_rf, results10_rf]\n",
    "for idx, i in enumerate(results_list_rf):\n",
    "    prob = i['predicted_prob']\n",
    "    # getting roc\n",
    "    false_pos_rate, true_pos_rate, thresh = roc_curve(i['target'], prob)\n",
    "    i['max_tpr_split'] = true_pos_rate[false_pos_rate == 0].max()\n",
    "    i['split'] = idx + 1  # or use idx if you want 0-based\n",
    "\n",
    "# xgboost\n",
    "results_list_xgb = [results1_xgb, results2_xgb, results3_xgb, results4_xgb, results5_xgb,\n",
    "                               results6_xgb, results7_xgb, results8_xgb, results9_xgb, results10_xgb]\n",
    "for idx, i in enumerate(results_list_xgb):\n",
    "    prob = i['predicted_prob']\n",
    "    # getting roc\n",
    "    false_pos_rate, true_pos_rate, thresh = roc_curve(i['target'], prob)\n",
    "    i['max_tpr_split'] = true_pos_rate[false_pos_rate == 0].max()\n",
    "    i['split'] = idx + 1\n",
    "\n",
    "# ROCKET\n",
    "results_list_rocket = [results1_rocket, results2_rocket, results3_rocket, results4_rocket, results5_rocket,\n",
    "                               results6_rocket, results7_rocket, results8_rocket, results9_rocket, results10_rocket]\n",
    "for idx, i in enumerate(results_list_rocket):\n",
    "    prob = i['predicted_prob']\n",
    "    # getting roc\n",
    "    false_pos_rate, true_pos_rate, thresh = roc_curve(i['target'], prob)\n",
    "    i['max_tpr_split'] = true_pos_rate[false_pos_rate == 0].max()\n",
    "    i['split'] = idx + 1\n",
    "\n",
    "# storing the max tpr for 10 splits in a list\n",
    "max_tpr_rf_by_split = [df['max_tpr_split'].iloc[0] for df in results_list_rf]\n",
    "max_tpr_xgb_by_split = [df['max_tpr_split'].iloc[0] for df in results_list_xgb]\n",
    "max_tpr_rocket_by_split = [df['max_tpr_split'].iloc[0] for df in results_list_rocket]\n",
    "\n",
    "# results dataframe for storing the max tprs by model, time, and predictor type \n",
    "rf_multiples = 10*['Random Forest']\n",
    "rocket_multiples = 10*['ROCKET']\n",
    "xgb_multiples = 10*['XGBoost']\n",
    "multiples_15s = 10*['15']\n",
    "tpr_df_rf_15s = pd.DataFrame({\n",
    "    'time': multiples_15s,\n",
    "    'model': rf_multiples,\n",
    "    'predictors': \"Vehicle\",\n",
    "    'max_tpr': max_tpr_rf_by_split\n",
    "})\n",
    "tpr_df_xgb_15s = pd.DataFrame({\n",
    "    'time': multiples_15s,\n",
    "    'model': rocket_multiples,\n",
    "    'predictors': \"Vehicle\",\n",
    "    'max_tpr': max_tpr_xgb_by_split\n",
    "})\n",
    "tpr_df_rocket_15s = pd.DataFrame({\n",
    "    'time': multiples_15s,\n",
    "    'model': xgb_multiples,\n",
    "    'predictors': \"Vehicle\",\n",
    "    'max_tpr': max_tpr_rocket_by_split\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d33003",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr_df_all_15s = pd.concat([tpr_df_rf_15s, tpr_df_xgb_15s, tpr_df_rocket_15s], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfab6e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the results for random forest and xgboost\n",
    "# 30s\n",
    "results1_rf = pd.read_csv(\"rf_results1.csv\")\n",
    "results2_rf = pd.read_csv(\"rf_results2.csv\")\n",
    "results3_rf = pd.read_csv(\"rf_results3.csv\")\n",
    "results4_rf = pd.read_csv(\"rf_results4.csv\")\n",
    "results5_rf = pd.read_csv(\"rf_results5.csv\")\n",
    "results6_rf = pd.read_csv(\"rf_results6.csv\")\n",
    "results7_rf = pd.read_csv(\"rf_results7.csv\")\n",
    "results8_rf = pd.read_csv(\"rf_results8.csv\")\n",
    "results9_rf = pd.read_csv(\"rf_results9.csv\")\n",
    "results10_rf = pd.read_csv(\"rf_results10.csv\")\n",
    "\n",
    "\n",
    "results1_xgb = pd.read_csv(\"xgb_results1.csv\")\n",
    "results2_xgb = pd.read_csv(\"xgb_results2.csv\")\n",
    "results3_xgb = pd.read_csv(\"xgb_results3.csv\")\n",
    "results4_xgb = pd.read_csv(\"xgb_results4.csv\")\n",
    "results5_xgb = pd.read_csv(\"xgb_results5.csv\")\n",
    "results6_xgb = pd.read_csv(\"xgb_results6.csv\")\n",
    "results7_xgb = pd.read_csv(\"xgb_results7.csv\")\n",
    "results8_xgb = pd.read_csv(\"xgb_results8.csv\")\n",
    "results9_xgb = pd.read_csv(\"xgb_results9.csv\")\n",
    "results10_xgb = pd.read_csv(\"xgb_results10.csv\")\n",
    "\n",
    "results1_rocket = pd.read_csv(\"rocketresults_vehicle1.csv\")\n",
    "results2_rocket = pd.read_csv(\"rocketresults_vehicle2.csv\")\n",
    "results3_rocket = pd.read_csv(\"rocketresults_vehicle3.csv\")\n",
    "results4_rocket = pd.read_csv(\"rocketresults_vehicle4.csv\")\n",
    "results5_rocket = pd.read_csv(\"rocketresults_vehicle5.csv\")\n",
    "results6_rocket = pd.read_csv(\"rocketresults_vehicle6.csv\")\n",
    "results7_rocket = pd.read_csv(\"rocketresults_vehicle7.csv\")\n",
    "results8_rocket = pd.read_csv(\"rocketresults_vehicle8.csv\")\n",
    "results9_rocket = pd.read_csv(\"rocketresults_vehicle9.csv\")\n",
    "results10_rocket = pd.read_csv(\"rocketresults_vehicle10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d285e4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# binding all results files for a model and calculating max true positive rate for each split\n",
    "# random forest \n",
    "results_list_rf = [results1_rf, results2_rf, results3_rf, results4_rf, results5_rf,\n",
    "                results6_rf, results7_rf, results8_rf, results9_rf, results10_rf]\n",
    "for idx, i in enumerate(results_list_rf):\n",
    "    prob = i['predicted_prob']\n",
    "    # getting roc\n",
    "    false_pos_rate, true_pos_rate, thresh = roc_curve(i['target'], prob)\n",
    "    i['max_tpr_split'] = true_pos_rate[false_pos_rate == 0].max()\n",
    "    i['split'] = idx + 1  # or use idx if you want 0-based\n",
    "\n",
    "# xgboost\n",
    "results_list_xgb = [results1_xgb, results2_xgb, results3_xgb, results4_xgb, results5_xgb,\n",
    "                               results6_xgb, results7_xgb, results8_xgb, results9_xgb, results10_xgb]\n",
    "for idx, i in enumerate(results_list_xgb):\n",
    "    prob = i['predicted_prob']\n",
    "    # getting roc\n",
    "    false_pos_rate, true_pos_rate, thresh = roc_curve(i['target'], prob)\n",
    "    i['max_tpr_split'] = true_pos_rate[false_pos_rate == 0].max()\n",
    "    i['split'] = idx + 1\n",
    "\n",
    "# ROCKET\n",
    "results_list_rocket = [results1_rocket, results2_rocket, results3_rocket, results4_rocket, results5_rocket,\n",
    "                               results6_rocket, results7_rocket, results8_rocket, results9_rocket, results10_rocket]\n",
    "for idx, i in enumerate(results_list_rocket):\n",
    "    prob = i['predicted_prob']\n",
    "    # getting roc\n",
    "    false_pos_rate, true_pos_rate, thresh = roc_curve(i['target'], prob)\n",
    "    i['max_tpr_split'] = true_pos_rate[false_pos_rate == 0].max()\n",
    "    i['split'] = idx + 1\n",
    "\n",
    "# storing the max tpr for 10 splits in a list\n",
    "max_tpr_rf_by_split = [df['max_tpr_split'].iloc[0] for df in results_list_rf]\n",
    "max_tpr_xgb_by_split = [df['max_tpr_split'].iloc[0] for df in results_list_xgb]\n",
    "max_tpr_rocket_by_split = [df['max_tpr_split'].iloc[0] for df in results_list_rocket]\n",
    "\n",
    "# results dataframe for storing the max tprs by model, time, and predictor type \n",
    "multiples_30s = 10*['30']\n",
    "tpr_df_rf_30s = pd.DataFrame({\n",
    "    'time': multiples_30s,\n",
    "    'model': rf_multiples,\n",
    "    'predictors': \"Vehicle\",\n",
    "    'max_tpr': max_tpr_rf_by_split\n",
    "})\n",
    "tpr_df_xgb_30s = pd.DataFrame({\n",
    "    'time': multiples_30s,\n",
    "    'model': rocket_multiples,\n",
    "    'predictors': \"Vehicle\",\n",
    "    'max_tpr': max_tpr_xgb_by_split\n",
    "})\n",
    "tpr_df_rocket_30s = pd.DataFrame({\n",
    "    'time': multiples_30s,\n",
    "    'model': xgb_multiples,\n",
    "    'predictors': \"Vehicle\",\n",
    "    'max_tpr': max_tpr_rocket_by_split\n",
    "})\n",
    "tpr_df_all_30s = pd.concat([tpr_df_rf_30s, tpr_df_xgb_30s, tpr_df_rocket_30s], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f44e0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c80667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the results for random forest and xgboost\n",
    "# 45s\n",
    "results1_rf = pd.read_csv(\"rf_results1.csv\")\n",
    "results2_rf = pd.read_csv(\"rf_results2.csv\")\n",
    "results3_rf = pd.read_csv(\"rf_results3.csv\")\n",
    "results4_rf = pd.read_csv(\"rf_results4.csv\")\n",
    "results5_rf = pd.read_csv(\"rf_results5.csv\")\n",
    "results6_rf = pd.read_csv(\"rf_results6.csv\")\n",
    "results7_rf = pd.read_csv(\"rf_results7.csv\")\n",
    "results8_rf = pd.read_csv(\"rf_results8.csv\")\n",
    "results9_rf = pd.read_csv(\"rf_results9.csv\")\n",
    "results10_rf = pd.read_csv(\"rf_results10.csv\")\n",
    "\n",
    "\n",
    "results1_xgb = pd.read_csv(\"xgb_results1.csv\")\n",
    "results2_xgb = pd.read_csv(\"xgb_results2.csv\")\n",
    "results3_xgb = pd.read_csv(\"xgb_results3.csv\")\n",
    "results4_xgb = pd.read_csv(\"xgb_results4.csv\")\n",
    "results5_xgb = pd.read_csv(\"xgb_results5.csv\")\n",
    "results6_xgb = pd.read_csv(\"xgb_results6.csv\")\n",
    "results7_xgb = pd.read_csv(\"xgb_results7.csv\")\n",
    "results8_xgb = pd.read_csv(\"xgb_results8.csv\")\n",
    "results9_xgb = pd.read_csv(\"xgb_results9.csv\")\n",
    "results10_xgb = pd.read_csv(\"xgb_results10.csv\")\n",
    "\n",
    "results1_rocket = pd.read_csv(\"rocketresults_vehicle1.csv\")\n",
    "results2_rocket = pd.read_csv(\"rocketresults_vehicle2.csv\")\n",
    "results3_rocket = pd.read_csv(\"rocketresults_vehicle3.csv\")\n",
    "results4_rocket = pd.read_csv(\"rocketresults_vehicle4.csv\")\n",
    "results5_rocket = pd.read_csv(\"rocketresults_vehicle5.csv\")\n",
    "results6_rocket = pd.read_csv(\"rocketresults_vehicle6.csv\")\n",
    "results7_rocket = pd.read_csv(\"rocketresults_vehicle7.csv\")\n",
    "results8_rocket = pd.read_csv(\"rocketresults_vehicle8.csv\")\n",
    "results9_rocket = pd.read_csv(\"rocketresults_vehicle9.csv\")\n",
    "results10_rocket = pd.read_csv(\"rocketresults_vehicle10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1b9097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binding all results files for a model and calculating max true positive rate for each split\n",
    "# random forest \n",
    "results_list_rf = [results1_rf, results2_rf, results3_rf, results4_rf, results5_rf,\n",
    "                results6_rf, results7_rf, results8_rf, results9_rf, results10_rf]\n",
    "for idx, i in enumerate(results_list_rf):\n",
    "    prob = i['predicted_prob']\n",
    "    # getting roc\n",
    "    false_pos_rate, true_pos_rate, thresh = roc_curve(i['target'], prob)\n",
    "    i['max_tpr_split'] = true_pos_rate[false_pos_rate == 0].max()\n",
    "    i['split'] = idx + 1  # or use idx if you want 0-based\n",
    "\n",
    "# xgboost\n",
    "results_list_xgb = [results1_xgb, results2_xgb, results3_xgb, results4_xgb, results5_xgb,\n",
    "                               results6_xgb, results7_xgb, results8_xgb, results9_xgb, results10_xgb]\n",
    "for idx, i in enumerate(results_list_xgb):\n",
    "    prob = i['predicted_prob']\n",
    "    # getting roc\n",
    "    false_pos_rate, true_pos_rate, thresh = roc_curve(i['target'], prob)\n",
    "    i['max_tpr_split'] = true_pos_rate[false_pos_rate == 0].max()\n",
    "    i['split'] = idx + 1\n",
    "\n",
    "# ROCKET\n",
    "results_list_rocket = [results1_rocket, results2_rocket, results3_rocket, results4_rocket, results5_rocket,\n",
    "                               results6_rocket, results7_rocket, results8_rocket, results9_rocket, results10_rocket]\n",
    "for idx, i in enumerate(results_list_rocket):\n",
    "    prob = i['predicted_prob']\n",
    "    # getting roc\n",
    "    false_pos_rate, true_pos_rate, thresh = roc_curve(i['target'], prob)\n",
    "    i['max_tpr_split'] = true_pos_rate[false_pos_rate == 0].max()\n",
    "    i['split'] = idx + 1\n",
    "\n",
    "# storing the max tpr for 10 splits in a list\n",
    "max_tpr_rf_by_split = [df['max_tpr_split'].iloc[0] for df in results_list_rf]\n",
    "max_tpr_xgb_by_split = [df['max_tpr_split'].iloc[0] for df in results_list_xgb]\n",
    "max_tpr_rocket_by_split = [df['max_tpr_split'].iloc[0] for df in results_list_rocket]\n",
    "\n",
    "# results dataframe for storing the max tprs by model, time, and predictor type \n",
    "multiples_45s = 10*['45']\n",
    "tpr_df_rf_45s = pd.DataFrame({\n",
    "    'time': multiples_45s,\n",
    "    'model': rf_multiples,\n",
    "    'predictors': \"Vehicle\",\n",
    "    'max_tpr': max_tpr_rf_by_split\n",
    "})\n",
    "tpr_df_xgb_45s = pd.DataFrame({\n",
    "    'time': multiples_45s,\n",
    "    'model': rocket_multiples,\n",
    "    'predictors': \"Vehicle\",\n",
    "    'max_tpr': max_tpr_xgb_by_split\n",
    "})\n",
    "tpr_df_rocket_45s = pd.DataFrame({\n",
    "    'time': multiples_45s,\n",
    "    'model': xgb_multiples,\n",
    "    'predictors': \"Vehicle\",\n",
    "    'max_tpr': max_tpr_rocket_by_split\n",
    "})\n",
    "tpr_df_all_45s = pd.concat([tpr_df_rf_45s, tpr_df_xgb_45s, tpr_df_rocket_45s], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ed1856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the results for random forest and xgboost\n",
    "# 60s\n",
    "results1_rf = pd.read_csv(\"rf_results1.csv\")\n",
    "results2_rf = pd.read_csv(\"rf_results2.csv\")\n",
    "results3_rf = pd.read_csv(\"rf_results3.csv\")\n",
    "results4_rf = pd.read_csv(\"rf_results4.csv\")\n",
    "results5_rf = pd.read_csv(\"rf_results5.csv\")\n",
    "results6_rf = pd.read_csv(\"rf_results6.csv\")\n",
    "results7_rf = pd.read_csv(\"rf_results7.csv\")\n",
    "results8_rf = pd.read_csv(\"rf_results8.csv\")\n",
    "results9_rf = pd.read_csv(\"rf_results9.csv\")\n",
    "results10_rf = pd.read_csv(\"rf_results10.csv\")\n",
    "\n",
    "\n",
    "results1_xgb = pd.read_csv(\"xgb_results1.csv\")\n",
    "results2_xgb = pd.read_csv(\"xgb_results2.csv\")\n",
    "results3_xgb = pd.read_csv(\"xgb_results3.csv\")\n",
    "results4_xgb = pd.read_csv(\"xgb_results4.csv\")\n",
    "results5_xgb = pd.read_csv(\"xgb_results5.csv\")\n",
    "results6_xgb = pd.read_csv(\"xgb_results6.csv\")\n",
    "results7_xgb = pd.read_csv(\"xgb_results7.csv\")\n",
    "results8_xgb = pd.read_csv(\"xgb_results8.csv\")\n",
    "results9_xgb = pd.read_csv(\"xgb_results9.csv\")\n",
    "results10_xgb = pd.read_csv(\"xgb_results10.csv\")\n",
    "\n",
    "results1_rocket = pd.read_csv(\"rocketresults_vehicle1.csv\")\n",
    "results2_rocket = pd.read_csv(\"rocketresults_vehicle2.csv\")\n",
    "results3_rocket = pd.read_csv(\"rocketresults_vehicle3.csv\")\n",
    "results4_rocket = pd.read_csv(\"rocketresults_vehicle4.csv\")\n",
    "results5_rocket = pd.read_csv(\"rocketresults_vehicle5.csv\")\n",
    "results6_rocket = pd.read_csv(\"rocketresults_vehicle6.csv\")\n",
    "results7_rocket = pd.read_csv(\"rocketresults_vehicle7.csv\")\n",
    "results8_rocket = pd.read_csv(\"rocketresults_vehicle8.csv\")\n",
    "results9_rocket = pd.read_csv(\"rocketresults_vehicle9.csv\")\n",
    "results10_rocket = pd.read_csv(\"rocketresults_vehicle10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c40666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binding all results files for a model and calculating max true positive rate for each split\n",
    "# random forest \n",
    "results_list_rf = [results1_rf, results2_rf, results3_rf, results4_rf, results5_rf,\n",
    "                results6_rf, results7_rf, results8_rf, results9_rf, results10_rf]\n",
    "for idx, i in enumerate(results_list_rf):\n",
    "    prob = i['predicted_prob']\n",
    "    # getting roc\n",
    "    false_pos_rate, true_pos_rate, thresh = roc_curve(i['target'], prob)\n",
    "    i['max_tpr_split'] = true_pos_rate[false_pos_rate == 0].max()\n",
    "    i['split'] = idx + 1  # or use idx if you want 0-based\n",
    "\n",
    "# xgboost\n",
    "results_list_xgb = [results1_xgb, results2_xgb, results3_xgb, results4_xgb, results5_xgb,\n",
    "                               results6_xgb, results7_xgb, results8_xgb, results9_xgb, results10_xgb]\n",
    "for idx, i in enumerate(results_list_xgb):\n",
    "    prob = i['predicted_prob']\n",
    "    # getting roc\n",
    "    false_pos_rate, true_pos_rate, thresh = roc_curve(i['target'], prob)\n",
    "    i['max_tpr_split'] = true_pos_rate[false_pos_rate == 0].max()\n",
    "    i['split'] = idx + 1\n",
    "\n",
    "# ROCKET\n",
    "results_list_rocket = [results1_rocket, results2_rocket, results3_rocket, results4_rocket, results5_rocket,\n",
    "                               results6_rocket, results7_rocket, results8_rocket, results9_rocket, results10_rocket]\n",
    "for idx, i in enumerate(results_list_rocket):\n",
    "    prob = i['predicted_prob']\n",
    "    # getting roc\n",
    "    false_pos_rate, true_pos_rate, thresh = roc_curve(i['target'], prob)\n",
    "    i['max_tpr_split'] = true_pos_rate[false_pos_rate == 0].max()\n",
    "    i['split'] = idx + 1\n",
    "\n",
    "# storing the max tpr for 10 splits in a list\n",
    "max_tpr_rf_by_split = [df['max_tpr_split'].iloc[0] for df in results_list_rf]\n",
    "max_tpr_xgb_by_split = [df['max_tpr_split'].iloc[0] for df in results_list_xgb]\n",
    "max_tpr_rocket_by_split = [df['max_tpr_split'].iloc[0] for df in results_list_rocket]\n",
    "\n",
    "# results dataframe for storing the max tprs by model, time, and predictor type \n",
    "multiples_60s = 10*['60']\n",
    "tpr_df_rf_60s = pd.DataFrame({\n",
    "    'time': multiples_60s,\n",
    "    'model': rf_multiples,\n",
    "    'predictors': \"Vehicle\",\n",
    "    'max_tpr': max_tpr_rf_by_split\n",
    "})\n",
    "tpr_df_xgb_60s = pd.DataFrame({\n",
    "    'time': multiples_60s,\n",
    "    'model': rocket_multiples,\n",
    "    'predictors': \"Vehicle\",\n",
    "    'max_tpr': max_tpr_xgb_by_split\n",
    "})\n",
    "tpr_df_rocket_60s = pd.DataFrame({\n",
    "    'time': multiples_60s,\n",
    "    'model': xgb_multiples,\n",
    "    'predictors': \"Vehicle\",\n",
    "    'max_tpr': max_tpr_rocket_by_split\n",
    "})\n",
    "tpr_df_all_60s = pd.concat([tpr_df_rf_60s, tpr_df_xgb_60s, tpr_df_rocket_60s], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2421a2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the results for random forest and xgboost\n",
    "# 75s\n",
    "results1_rf = pd.read_csv(\"rf_results1.csv\")\n",
    "results2_rf = pd.read_csv(\"rf_results2.csv\")\n",
    "results3_rf = pd.read_csv(\"rf_results3.csv\")\n",
    "results4_rf = pd.read_csv(\"rf_results4.csv\")\n",
    "results5_rf = pd.read_csv(\"rf_results5.csv\")\n",
    "results6_rf = pd.read_csv(\"rf_results6.csv\")\n",
    "results7_rf = pd.read_csv(\"rf_results7.csv\")\n",
    "results8_rf = pd.read_csv(\"rf_results8.csv\")\n",
    "results9_rf = pd.read_csv(\"rf_results9.csv\")\n",
    "results10_rf = pd.read_csv(\"rf_results10.csv\")\n",
    "\n",
    "\n",
    "results1_xgb = pd.read_csv(\"xgb_results1.csv\")\n",
    "results2_xgb = pd.read_csv(\"xgb_results2.csv\")\n",
    "results3_xgb = pd.read_csv(\"xgb_results3.csv\")\n",
    "results4_xgb = pd.read_csv(\"xgb_results4.csv\")\n",
    "results5_xgb = pd.read_csv(\"xgb_results5.csv\")\n",
    "results6_xgb = pd.read_csv(\"xgb_results6.csv\")\n",
    "results7_xgb = pd.read_csv(\"xgb_results7.csv\")\n",
    "results8_xgb = pd.read_csv(\"xgb_results8.csv\")\n",
    "results9_xgb = pd.read_csv(\"xgb_results9.csv\")\n",
    "results10_xgb = pd.read_csv(\"xgb_results10.csv\")\n",
    "\n",
    "results1_rocket = pd.read_csv(\"rocketresults_vehicle1.csv\")\n",
    "results2_rocket = pd.read_csv(\"rocketresults_vehicle2.csv\")\n",
    "results3_rocket = pd.read_csv(\"rocketresults_vehicle3.csv\")\n",
    "results4_rocket = pd.read_csv(\"rocketresults_vehicle4.csv\")\n",
    "results5_rocket = pd.read_csv(\"rocketresults_vehicle5.csv\")\n",
    "results6_rocket = pd.read_csv(\"rocketresults_vehicle6.csv\")\n",
    "results7_rocket = pd.read_csv(\"rocketresults_vehicle7.csv\")\n",
    "results8_rocket = pd.read_csv(\"rocketresults_vehicle8.csv\")\n",
    "results9_rocket = pd.read_csv(\"rocketresults_vehicle9.csv\")\n",
    "results10_rocket = pd.read_csv(\"rocketresults_vehicle10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6f4b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binding all results files for a model and calculating max true positive rate for each split\n",
    "# random forest \n",
    "results_list_rf = [results1_rf, results2_rf, results3_rf, results4_rf, results5_rf,\n",
    "                results6_rf, results7_rf, results8_rf, results9_rf, results10_rf]\n",
    "for idx, i in enumerate(results_list_rf):\n",
    "    prob = i['predicted_prob']\n",
    "    # getting roc\n",
    "    false_pos_rate, true_pos_rate, thresh = roc_curve(i['target'], prob)\n",
    "    i['max_tpr_split'] = true_pos_rate[false_pos_rate == 0].max()\n",
    "    i['split'] = idx + 1  # or use idx if you want 0-based\n",
    "\n",
    "# xgboost\n",
    "results_list_xgb = [results1_xgb, results2_xgb, results3_xgb, results4_xgb, results5_xgb,\n",
    "                               results6_xgb, results7_xgb, results8_xgb, results9_xgb, results10_xgb]\n",
    "for idx, i in enumerate(results_list_xgb):\n",
    "    prob = i['predicted_prob']\n",
    "    # getting roc\n",
    "    false_pos_rate, true_pos_rate, thresh = roc_curve(i['target'], prob)\n",
    "    i['max_tpr_split'] = true_pos_rate[false_pos_rate == 0].max()\n",
    "    i['split'] = idx + 1\n",
    "\n",
    "# ROCKET\n",
    "results_list_rocket = [results1_rocket, results2_rocket, results3_rocket, results4_rocket, results5_rocket,\n",
    "                               results6_rocket, results7_rocket, results8_rocket, results9_rocket, results10_rocket]\n",
    "for idx, i in enumerate(results_list_rocket):\n",
    "    prob = i['predicted_prob']\n",
    "    # getting roc\n",
    "    false_pos_rate, true_pos_rate, thresh = roc_curve(i['target'], prob)\n",
    "    i['max_tpr_split'] = true_pos_rate[false_pos_rate == 0].max()\n",
    "    i['split'] = idx + 1\n",
    "\n",
    "# storing the max tpr for 10 splits in a list\n",
    "max_tpr_rf_by_split = [df['max_tpr_split'].iloc[0] for df in results_list_rf]\n",
    "max_tpr_xgb_by_split = [df['max_tpr_split'].iloc[0] for df in results_list_xgb]\n",
    "max_tpr_rocket_by_split = [df['max_tpr_split'].iloc[0] for df in results_list_rocket]\n",
    "\n",
    "# results dataframe for storing the max tprs by model, time, and predictor type \n",
    "multiples_75s = 10*['75']\n",
    "tpr_df_rf_75s = pd.DataFrame({\n",
    "    'time': multiples_75s,\n",
    "    'model': rf_multiples,\n",
    "    'predictors': \"Vehicle\",\n",
    "    'max_tpr': max_tpr_rf_by_split\n",
    "})\n",
    "tpr_df_xgb_75s = pd.DataFrame({\n",
    "    'time': multiples_75s,\n",
    "    'model': rocket_multiples,\n",
    "    'predictors': \"Vehicle\",\n",
    "    'max_tpr': max_tpr_xgb_by_split\n",
    "})\n",
    "tpr_df_rocket_75s = pd.DataFrame({\n",
    "    'time': multiples_75s,\n",
    "    'model': xgb_multiples,\n",
    "    'predictors': \"Vehicle\",\n",
    "    'max_tpr': max_tpr_rocket_by_split\n",
    "})\n",
    "tpr_df_all_75s = pd.concat([tpr_df_rf_75s, tpr_df_xgb_75s, tpr_df_rocket_75s], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7cbe4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the results for random forest and xgboost\n",
    "# 90s\n",
    "results1_rf = pd.read_csv(\"rf_results1.csv\")\n",
    "results2_rf = pd.read_csv(\"rf_results2.csv\")\n",
    "results3_rf = pd.read_csv(\"rf_results3.csv\")\n",
    "results4_rf = pd.read_csv(\"rf_results4.csv\")\n",
    "results5_rf = pd.read_csv(\"rf_results5.csv\")\n",
    "results6_rf = pd.read_csv(\"rf_results6.csv\")\n",
    "results7_rf = pd.read_csv(\"rf_results7.csv\")\n",
    "results8_rf = pd.read_csv(\"rf_results8.csv\")\n",
    "results9_rf = pd.read_csv(\"rf_results9.csv\")\n",
    "results10_rf = pd.read_csv(\"rf_results10.csv\")\n",
    "\n",
    "\n",
    "results1_xgb = pd.read_csv(\"xgb_results1.csv\")\n",
    "results2_xgb = pd.read_csv(\"xgb_results2.csv\")\n",
    "results3_xgb = pd.read_csv(\"xgb_results3.csv\")\n",
    "results4_xgb = pd.read_csv(\"xgb_results4.csv\")\n",
    "results5_xgb = pd.read_csv(\"xgb_results5.csv\")\n",
    "results6_xgb = pd.read_csv(\"xgb_results6.csv\")\n",
    "results7_xgb = pd.read_csv(\"xgb_results7.csv\")\n",
    "results8_xgb = pd.read_csv(\"xgb_results8.csv\")\n",
    "results9_xgb = pd.read_csv(\"xgb_results9.csv\")\n",
    "results10_xgb = pd.read_csv(\"xgb_results10.csv\")\n",
    "\n",
    "results1_rocket = pd.read_csv(\"rocketresults_vehicle1.csv\")\n",
    "results2_rocket = pd.read_csv(\"rocketresults_vehicle2.csv\")\n",
    "results3_rocket = pd.read_csv(\"rocketresults_vehicle3.csv\")\n",
    "results4_rocket = pd.read_csv(\"rocketresults_vehicle4.csv\")\n",
    "results5_rocket = pd.read_csv(\"rocketresults_vehicle5.csv\")\n",
    "results6_rocket = pd.read_csv(\"rocketresults_vehicle6.csv\")\n",
    "results7_rocket = pd.read_csv(\"rocketresults_vehicle7.csv\")\n",
    "results8_rocket = pd.read_csv(\"rocketresults_vehicle8.csv\")\n",
    "results9_rocket = pd.read_csv(\"rocketresults_vehicle9.csv\")\n",
    "results10_rocket = pd.read_csv(\"rocketresults_vehicle10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf17fb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# binding all results files for a model and calculating max true positive rate for each split\n",
    "# random forest \n",
    "results_list_rf = [results1_rf, results2_rf, results3_rf, results4_rf, results5_rf,\n",
    "                results6_rf, results7_rf, results8_rf, results9_rf, results10_rf]\n",
    "for idx, i in enumerate(results_list_rf):\n",
    "    prob = i['predicted_prob']\n",
    "    # getting roc\n",
    "    false_pos_rate, true_pos_rate, thresh = roc_curve(i['target'], prob)\n",
    "    i['max_tpr_split'] = true_pos_rate[false_pos_rate == 0].max()\n",
    "    i['split'] = idx + 1  # or use idx if you want 0-based\n",
    "\n",
    "# xgboost\n",
    "results_list_xgb = [results1_xgb, results2_xgb, results3_xgb, results4_xgb, results5_xgb,\n",
    "                               results6_xgb, results7_xgb, results8_xgb, results9_xgb, results10_xgb]\n",
    "for idx, i in enumerate(results_list_xgb):\n",
    "    prob = i['predicted_prob']\n",
    "    # getting roc\n",
    "    false_pos_rate, true_pos_rate, thresh = roc_curve(i['target'], prob)\n",
    "    i['max_tpr_split'] = true_pos_rate[false_pos_rate == 0].max()\n",
    "    i['split'] = idx + 1\n",
    "\n",
    "# ROCKET\n",
    "results_list_rocket = [results1_rocket, results2_rocket, results3_rocket, results4_rocket, results5_rocket,\n",
    "                               results6_rocket, results7_rocket, results8_rocket, results9_rocket, results10_rocket]\n",
    "for idx, i in enumerate(results_list_rocket):\n",
    "    prob = i['predicted_prob']\n",
    "    # getting roc\n",
    "    false_pos_rate, true_pos_rate, thresh = roc_curve(i['target'], prob)\n",
    "    i['max_tpr_split'] = true_pos_rate[false_pos_rate == 0].max()\n",
    "    i['split'] = idx + 1\n",
    "\n",
    "# storing the max tpr for 10 splits in a list\n",
    "max_tpr_rf_by_split = [df['max_tpr_split'].iloc[0] for df in results_list_rf]\n",
    "max_tpr_xgb_by_split = [df['max_tpr_split'].iloc[0] for df in results_list_xgb]\n",
    "max_tpr_rocket_by_split = [df['max_tpr_split'].iloc[0] for df in results_list_rocket]\n",
    "\n",
    "# results dataframe for storing the max tprs by model, time, and predictor type \n",
    "multiples_90s = 10*['90']\n",
    "tpr_df_rf_90s = pd.DataFrame({\n",
    "    'time': multiples_90s,\n",
    "    'model': rf_multiples,\n",
    "    'predictors': \"Vehicle\",\n",
    "    'max_tpr': max_tpr_rf_by_split\n",
    "})\n",
    "tpr_df_xgb_90s = pd.DataFrame({\n",
    "    'time': multiples_90s,\n",
    "    'model': rocket_multiples,\n",
    "    'predictors': \"Vehicle\",\n",
    "    'max_tpr': max_tpr_xgb_by_split\n",
    "})\n",
    "tpr_df_rocket_90s = pd.DataFrame({\n",
    "    'time': multiples_90s,\n",
    "    'model': xgb_multiples,\n",
    "    'predictors': \"Vehicle\",\n",
    "    'max_tpr': max_tpr_rocket_by_split\n",
    "})\n",
    "tpr_df_all_90s = pd.concat([tpr_df_rf_90s, tpr_df_xgb_90s, tpr_df_rocket_90s], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b34ffd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tpr_df_comb = pd.concat([tpr_df_all_15s, tpr_df_all_30s, tpr_df_all_45s, tpr_df_all_60s, tpr_df_all_75s, tpr_df_all_90s], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd44856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving csv file\n",
    "tpr_df_comb.to_csv('max_tpr_df_veh.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
